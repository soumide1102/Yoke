studyIDX,YOKE_TORCH_ENV,KNODES,NGPUS,NUM_WORKERS,BATCH_SIZE,NTRN_BATCH,NVAL_BATCH,ANCHOR_LR,NUM_CYCLES,MIN_FRACTION,TERMINAL_STEPS,WARMUP_STEPS,train_script
# batch_size=16 causes CUDA OOM error
# batch_size=8 with 100 batches per epoch yields ~4min epochs
#
# batch_size=8 with 1500 batches per epoch, ~60min epochs.
# 500 batches per validation, ~20min val-epoch.
#1,torch_ch_gpu_241112,1,4,2,1,800,200,2.0e-3,0.5,0.5,800,400,train_lsc_policy.py
1,torch_ch_gpu_241112,1,4,2,8,800,200,5.0e-4,0.5,0.5,800,400,train_lsc_policy.py

